---
title: 关于知识图谱中的命名实体识别（NER）
top: false
cover: false
toc: true
mathjax: true
date: 2021-12-06 11:44:57
password:
summary:
tags:
- 知识图谱
- NER
- 命名实体识别
categories:
- 算法
- NLP
---

# 写在前面
命名实体识别（Named Entity Recognition，NER），是指识别文本中具有特定意义的实体，可能包括人名、地名、机构名、专有名词等。通常包括两部分：
1. 实体边界识别；
2. 确定实体识别（特定的人名、地名、机构名称等）

# NER现状
NER当前并不算是一个大热的研究课题，因为学术界部分学者认为这是一个已经解决的问题。当然也有学者认为这个问题还没有得到很好地解决，原因主要有：命名实体识别只是在有限的文本类型（主要是新闻语料中）和实体类别（主要是人名、地名、组织机构名）中取得了不错的效果；与其他信息检索领域相比，实体命名评测预料较小，容易产生过拟合；命名实体识别更侧重高召回率，但在信息检索领域，高准确率更重要；通用的识别多种类型的命名实体的系统性能很差。

## 中文NER问题
中文的命名实体识别与英文相比，挑战更大，目前未解决的难题很多。英文中的命名实体具有明显形式标志，比如空格分割、首字母大写等，英文的实体切分重点是确定实体的类别。和英文相比，中文命名实体识别任务更加复杂，而且相对实体类别标注子任务，实体边界识别更加困难。
中文NER的难点主要在于：
1. 中文文本没有类似英文文本中空格之类的显示标示词的边界标示符，命名实体识别的第一步就是确定词的边界，即分词。
2. 中文分词和命名实体识别互相影响。
3. 除了英文中定义的实体，外国人名译名和地名译名是存在于中文中的两类特殊实体类型。
4. 现代中文文本，尤其是网络中文文本，常常中英文交替混合，中文NER的任务还包括识别其中的英文命名实体。
5. 不同的命名实体具有不同的内部特征，不可能用一个统一的模型来刻画所有的实体内部特征。

# NER方法
当前命名实体识别的主要技术方法分为：基于规则和词典的方法、基于统计的方法、二者混合的方法、神经网络的方法等。

## 基于规则和词典的方法
基于规则的方法多采用**语言学专家手工构造规则模板**，选用特征包括统计信息、标点符号、关键字、指示词和方向次、位置词（如尾字）、中心词等方法，以模式和字符串相匹配为主要手段，这类系统大多依赖于知识库和词典的建立。

此类方法的主要缺点在于：
1. 依赖于知识库和词典等先验知识的建立。
2. 系统可以执行不好，对于不同的系统需要语言学家重新书写规则。
3. 代价太大，系统建设周期长。

## 基于统计的方法
基于统计机器学习的方法主要包括：隐马尔可夫模型（Hidden Markov Model， HMM）、最大熵（Maxmium Entropy）、支持向量机（Support Vector Machine，SVM）、条件随机场（Conditional Random Fields，CRF）。

此类方法的特点：
1. 最大熵模型有较好的通用性，主要缺点是训练时间复杂性高。
2. 条件随机场特征灵活、全局最优的标注框架，但同时存在收敛速度慢、训练时间长的问题。
3. 隐马尔可夫模型再训练和识别时的速度要快一些，Viterbi算法求解命名实体类别序列的效率较高。
4. 最大熵和支持向量机在正确率上要比隐马尔可夫模型高。
5. 基于统计的方法对语料库的依赖也比较大。

## 混合方法
自然语言处理并不完全是一个随机过程，单独使用基于统计的方法使状态搜索空间非常庞大，必须借助规则知识提前进行过滤修剪处理。目前几乎没有单纯使用统计模型而不使用规则知识的命名实体识别系统，在很多情况下是使用混合方法，主要包括：
1. 统计学系方法之间或内部层叠融合。
2. 规则、词典和机器学习方法之间的融合，其核心是融合方法技术。在基于统计的学习方法中引入部分规则，将机器学习和人工知识结合起来。
3. 将各类模型、算法结合起来，将前一级模型的结果作为下一级的训练数据，并用这些训练数据对模型进行训练，得到下一级模型。

## 基于神经网络的方法
近年来，随着硬件能力的发展以及词的分布式表示（word embedding）的出现，神经网络成为可以有效处理许多NLP任务的模型。主要模型有NN/CNN-CRF、RNN-CRF、LSTM-CRF。

神经网络可以分为以下几个步骤：
1. 对于序列标注任务（如CWS、POS、NER）的处理方式是类似的，将token从离散one-hot表示映射到低维空间中成为稠密的embedding。
2. 将句子的embedding序列输入到RNN中，用神经网络自动提取特征。
3. Softmax来预测每个token的标签。

优点：
1. 神经网络模型的训练成为一个端到端的整体过程，而非传统的pipeline。
2. 不依赖特征工程，是一种数据驱动的方法。

缺点：
1. 网络变种多，对参数设置依赖大。
2. 模型可解释性差。
3. 每个token打标签的过程中是独立的额分类，不能直接利用上文已经预测的标签。

# 总结
从语言分析的全过程来看，命名实体识别属于词法分析中未登录词识别的范畴。命名实体识别是未登录词中数量最多、识别难度最大、对分词效果影响最大的问题，同时它也是信息抽取、信息检索、机器翻译、问答系统等多种自然语言处理技术必不可少的组成部分。

[原文链接](https://www.cnblogs.com/huangyc/p/10064853.html)